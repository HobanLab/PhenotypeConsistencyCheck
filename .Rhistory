# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
colnames(results_matrix)
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
results_matrix[,nominal_columns]
results_matrix[,nominal_columns]
sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
View(sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE))
sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[1,nominal_columns]), na.last = TRUE)
as.vector(sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE))
sort(as.vector(initial_phenotype_measurement_df[1,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[1,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[2,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[3,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[15,nominal_columns]), na.last = TRUE)
sort(as.double(final_phenotype_measurement_df[15,nominal_columns]), na.last = TRUE)
sort(as.double(final_phenotype_measurement_df[16,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[16,nominal_columns]), na.last = TRUE)
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
results_matrix[i,nominal_columns]
# for loop that iterates through the various columns
for (i in 1:29) {
results_matrix[i, 17:21] <- sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,ordinal_columns] <- results_df[,ordinal_columns] == 1
results_df[,ordinal_columns]
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,ordinal_columns] <- results_df[,ordinal_columns] == 1
results_df[,ordinal_columns]
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
results_matrix[,ordinal_columns]
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
# for loop that iterates through the various columns
for (i in 1:29) {
results_matrix[i, 17:21] <- sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,ordinal_columns] <- results_df[,ordinal_columns] == 1
results_df[,ordinal_columns]
results_df[,nominal_columns]
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,c(ordinal_columns, nominal_columns)] <- results_df[,c(ordinal_columns,nominal_columns)] == 1
results_df[,c(ordinal_columns, nominal_columns)]
results_df
col_names(results_df)
colnames(results_df)
results_df
# approaches to creating the true/false table IN PROGRESS
categorical_table_results <- matrix(nrow = length(ordinal_columns), ncol = 2)
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
for (i in 1:length(ordinal_columns)) {
col_index <- ordinal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
nominal_columns
length(nominal_columns)
for (i in 1:length(ordinal_columns)) {
col_index <- ordinal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
# approaches to creating the true/false table IN PROGRESS
categorical_table_results <- matrix(nrow = length(ordinal_columns), ncol = 2)
categorical_table_results
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
length(ordinal_columns)
ordinal_columns
nominal_columns
# approaches to creating the true/false table IN PROGRESS
categorical_table_results <- matrix(nrow = length(ordinal_columns), ncol = 2)
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
categorical_table_results
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
categorical_table_results
for (i in 1:length(ordinal_columns)) {
col_index <- ordinal_columns[i]  # Get the actual column index
categorical_table_results[i,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
categorical_table_results
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
setwd(phenotype.wd)
initial_phenotype_measurement_df <- read.csv("butternut_hybrid_spreadsheet_Salas.csv")
final_phenotype_measurement_df <- read.csv("2025_01_22_blind_consistency_check.csv")
# remove rows from dataset
initial_phenotype_measurement_df <- initial_phenotype_measurement_df[-c(30:999),]
final_phenotype_measurement_df <- final_phenotype_measurement_df[-c(30:999),]
# convert n/a to NA
initial_phenotype_measurement_df[initial_phenotype_measurement_df == "n/a"] <- NA
final_phenotype_measurement_df[final_phenotype_measurement_df == "n/a"] <- NA
# ordinal columns
ordinal_columns <- c(6:16,22,38,44)
# nominal columns
nominal_columns <- c(39:43)
# continuous columns
continuous_columns <- c(17:21,23:27,28:32,33:37)
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
setwd(phenotype.wd)
initial_phenotype_measurement_df <- read.csv("butternut_hybrid_spreadsheet_Salas.csv")
final_phenotype_measurement_df <- read.csv("2025_01_22_blind_consistency_check.csv")
# remove rows from dataset
initial_phenotype_measurement_df <- initial_phenotype_measurement_df[-c(30:999),]
final_phenotype_measurement_df <- final_phenotype_measurement_df[-c(30:999),]
# convert n/a to NA
initial_phenotype_measurement_df[initial_phenotype_measurement_df == "n/a"] <- NA
final_phenotype_measurement_df[final_phenotype_measurement_df == "n/a"] <- NA
# ordinal columns
ordinal_columns <- c(6:16,22,38,44)
# nominal columns
nominal_columns <- c(39:43)
# continuous columns
continuous_columns <- c(17:21,23:27,28:32,33:37)
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
results_matrix
results_matrix
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
results_matrix[,ordinal_columns]
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
results_matrix[i,nominal_columns]
results_matrix[,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[,nominal_columns]), na.last = TRUE)
# iterate through each row after sorting nominal columns in descending order and use true false to compare the leaflet counts
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
sort(as.double(initial_phenotype_measurement_df[i,nominal_columns])
, na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[1:5,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[1,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[,nominal_columns]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[2,nominal_columns]), na.last = TRUE)
sort(as.double(final_phenotype_measurement_df[2,nominal_columns]), na.last = TRUE)
# for loop that iterates through the various columns and calculates the percent change
for (i in 1:nrow(results_matrix)) {
results_matrix[i, 17:21] <- 100*(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- 100*(sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- 100*(sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- 100*(sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,c(ordinal_columns, nominal_columns)] <- results_df[,c(ordinal_columns,nominal_columns)] == 1
results_df[,c(ordinal_columns, nominal_columns)]
# approaches to creating the table that calculates the percentage of TRUE values that matched after comparing the columns of both tables
categorical_table_results <- as.data.frame(matrix(nrow = length(ordinal_columns)+length(nominal_columns), ncol = 2))
categorical_table_results
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i+13,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i+13,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
for (j in 1:length(ordinal_columns)) {
if (j < 14){
col_index <- ordinal_columns[j]  # Get the actual column index
categorical_table_results[j,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[j,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
else {
categorical_table_results[j+5,1] <- colnames(results_df)[col_index+6]
categorical_table_results[j+5,2] <- 100 * (sum(results_df[[col_index+6]], na.rm = TRUE) / sum(!is.na(results_df[[col_index+6]])))
}
}
categorical_table_results
write.csv(categorical_table_results,paste0(phenotype.wd, "categoricaltableresults.csv"))
sum(!is.na(results_df[[col_index+6]])))
sum(!is.na(results_df[[col_index+6]]))
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
setwd(phenotype.wd)
initial_phenotype_measurement_df <- read.csv("butternut_hybrid_spreadsheet_Salas.csv")
final_phenotype_measurement_df <- read.csv("2025_01_22_blind_consistency_check.csv")
# remove rows from dataset
initial_phenotype_measurement_df <- initial_phenotype_measurement_df[-c(30:999),]
final_phenotype_measurement_df <- final_phenotype_measurement_df[-c(30:999),]
# convert n/a to NA
initial_phenotype_measurement_df[initial_phenotype_measurement_df == "n/a"] <- NA
final_phenotype_measurement_df[final_phenotype_measurement_df == "n/a"] <- NA
# ordinal columns
ordinal_columns <- c(6:16,22,38,44)
# nominal columns
nominal_columns <- c(39:43)
# continuous columns
continuous_columns <- c(17:21,23:27,28:32,33:37)
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
# iterate through each row after sorting nominal columns in ascending order and use true false to compare the leaflet counts
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
# for loop that iterates through the various columns and calculates the percent change
for (i in 1:nrow(results_matrix)) {
results_matrix[i, 17:21] <- 100*(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- 100*(sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- 100*(sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- 100*(sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
results_df
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,c(ordinal_columns, nominal_columns)] <- results_df[,c(ordinal_columns,nominal_columns)] == 1
final_results_df <- results_df[,sort(c(continuous_columns,nominal_columns,ordinal_columns))]
final_results_df
# approaches to creating the table that calculates the percentage of TRUE values that matched after comparing the columns of both tables
categorical_table_results <- as.data.frame(matrix(nrow = length(ordinal_columns)+length(nominal_columns), ncol = 2))
categorical_table_results
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i+13,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i+13,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
col_index
nominal_columns
for (j in 1:length(ordinal_columns)) {
if (j < 14){
col_index <- ordinal_columns[j]  # Get the actual column index
categorical_table_results[j,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[j,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
else {
categorical_table_results[j+5,1] <- colnames(results_df)[col_index+6]
categorical_table_results[j+5,2] <- 100 * (sum(results_df[[col_index+6]], na.rm = TRUE) / sum(!is.na(results_df[[col_index+6]])))
}
}
categorical_table_results
sum
sum(!is.na(results_df[[col_index]]))
!is.na(results_df[[col_index]]
)
col_index
categorical_table_results
categorical_table_results
# continuousTable_results percent change
continuous_table_Average_percentChange <- as.data.frame(matrix(nrow = length(continuous_columns), ncol = 2))
continuous_table_Average_percentChange
for (i in 1:length(continuous_columns)) {
col_index <- continuous_columns[i]  # Get the actual column index
continuous_table_Average_percentChange[i,1] <- colnames(results_df)[col_index]  # Store column name
continuous_table_Average_percentChange[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
continuous_table_Average_percentChange
sum(results_df[[col_index]], na.rm = TRUE)
col_index
results_df[[col_index]]
results_df[[col_index]]
sum(!is.na(results_df[[col_index]])
)
(sum(results_df[[col_index]], na.rm = TRUE)
)
sum(!is.na(results_df[[col_index]]))
results_df[[col_index]]
(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE)
)
sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE))
(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE))-sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE))-sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
((sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE))-sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
setwd(phenotype.wd)
initial_phenotype_measurement_df <- read.csv("butternut_hybrid_spreadsheet_Salas.csv")
final_phenotype_measurement_df <- read.csv("2025_01_22_blind_consistency_check.csv")
# remove rows from dataset
initial_phenotype_measurement_df <- initial_phenotype_measurement_df[-c(30:999),]
final_phenotype_measurement_df <- final_phenotype_measurement_df[-c(30:999),]
# convert n/a to NA
initial_phenotype_measurement_df[initial_phenotype_measurement_df == "n/a"] <- NA
final_phenotype_measurement_df[final_phenotype_measurement_df == "n/a"] <- NA
# ordinal columns
ordinal_columns <- c(6:16,22,38,44)
# nominal columns
nominal_columns <- c(39:43)
# continuous columns
continuous_columns <- c(17:21,23:27,28:32,33:37)
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
# iterate through each row after sorting nominal columns in ascending order and use true false to compare the leaflet counts
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
# for loop that iterates through the various columns and calculates the percent change
for (i in 1:nrow(results_matrix)) {
results_matrix[i, 17:21] <- 100*(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- 100*(sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- 100*(sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- 100*(sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
results_df
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,c(ordinal_columns, nominal_columns)] <- results_df[,c(ordinal_columns,nominal_columns)] == 1
final_results_df <- results_df[,sort(c(continuous_columns,nominal_columns,ordinal_columns))]
final_results_df
final_results_df[,c(continuous_columns)]
# approaches to creating the table that calculates the percentage of TRUE values that matched after comparing the columns of both tables
categorical_table_results <- as.data.frame(matrix(nrow = length(ordinal_columns)+length(nominal_columns), ncol = 2))
for (i in 1:length(nominal_columns)) {
col_index <- nominal_columns[i]  # Get the actual column index
categorical_table_results[i+13,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[i+13,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
for (j in 1:length(ordinal_columns)) {
if (j < 14){
col_index <- ordinal_columns[j]  # Get the actual column index
categorical_table_results[j,1] <- colnames(results_df)[col_index]  # Store column name
categorical_table_results[j,2] <- 100 * (sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]])))
}
else {
categorical_table_results[j+5,1] <- colnames(results_df)[col_index+6]
categorical_table_results[j+5,2] <- 100 * (sum(results_df[[col_index+6]], na.rm = TRUE) / sum(!is.na(results_df[[col_index+6]])))
}
}
categorical_table_results
# continuousTable_results percent change
continuous_table_Average_percentChange <- as.data.frame(matrix(nrow = length(continuous_columns), ncol = 2))
for (i in 1:length(continuous_columns)) {
col_index <- continuous_columns[i]  # Get the actual column index
continuous_table_Average_percentChange[i,1] <- colnames(results_df)[col_index]  # Store column name
continuous_table_Average_percentChange[i,2] <- sum(results_df[[col_index]], na.rm = TRUE) / sum(!is.na(results_df[[col_index]]))
}
continuous_table_Average_percentChange
results_matrix
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
results_matrix
# iterate through each row after sorting nominal columns in ascending order and use true false to compare the leaflet counts
for (i in 1:nrow(initial_phenotype_measurement_df)) {
results_matrix[i,nominal_columns] <- sort(as.double(initial_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE) == sort(as.double(final_phenotype_measurement_df[i,nominal_columns]), na.last = TRUE)
}
# for loop that iterates through the various columns and calculates the percent change
for (i in 1:nrow(results_matrix)) {
results_matrix[i, 17:21] <- 100*(sort(as.double(final_phenotype_measurement_df[i,17:21]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,17:21]), na.last = TRUE)
results_matrix[i, 23:27] <- 100*(sort(as.double(final_phenotype_measurement_df[i,23:27]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,23:27]), na.last = TRUE)
results_matrix[i, 28:32] <- 100*(sort(as.double(final_phenotype_measurement_df[i,28:32]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,28:32]), na.last = TRUE)
results_matrix[i, 33:37] <- 100*(sort(as.double(final_phenotype_measurement_df[i,33:37]), na.last = TRUE) - sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE))/sort(as.double(initial_phenotype_measurement_df[i,33:37]), na.last = TRUE)
}
# all the true false statements were turned to 1's and 0's after calling the  for loop. so we will want to change the matrix to a dataframe.
results_df <- data.frame(results_matrix)
results_df
# converting all the 1 and 0 values to TRUE or FALSE with boolean phrase
results_df[,c(ordinal_columns, nominal_columns)] <- results_df[,c(ordinal_columns,nominal_columns)] == 1
results_df[, continuous_columns]
continuous_results_df <- results_df[, continuous_columns]
continuous_results_df
write.csv(continuous_results_df, file = paste0(phenotype.wd, "continuousresultsPercentChange.csv"))
# this script outputs a matrix of 30 rows and 50 columns of continuous and categorical
# data as a result of comparing initial and final measurements of two matrices
# Create objects ----
phenotype.wd <- "C:/Users/gsalas/Documents/PhenotypeConsistencyCheck/"
setwd(phenotype.wd)
initial_phenotype_measurement_df <- read.csv("butternut_hybrid_spreadsheet_Salas.csv")
final_phenotype_measurement_df <- read.csv("2025_01_22_blind_consistency_check.csv")
# remove rows from dataset
initial_phenotype_measurement_df <- initial_phenotype_measurement_df[-c(30:999),]
final_phenotype_measurement_df <- final_phenotype_measurement_df[-c(30:999),]
# convert n/a to NA
initial_phenotype_measurement_df[initial_phenotype_measurement_df == "n/a"] <- NA
final_phenotype_measurement_df[final_phenotype_measurement_df == "n/a"] <- NA
# ordinal columns
ordinal_columns <- c(6:16,22,38,44)
# nominal columns
nominal_columns <- c(39:43)
# continuous columns
continuous_columns <- c(17:21,23:27,28:32,33:37)
# Create a matrix that will store the percent change and true or false statements
# and soft code the values for the rows and columns
results_matrix <- matrix(nrow = dim(initial_phenotype_measurement_df)[1], ncol = dim(initial_phenotype_measurement_df)[2])
# concatenate column names into the columns object
columns<-c(colnames(final_phenotype_measurement_df))
# add the column names to the results_matrix
colnames(results_matrix) <- columns
# vectorize the true or false parameters by comparing the lenticel shape columns between both matrices
results_matrix[,ordinal_columns] <- initial_phenotype_measurement_df[,ordinal_columns] == final_phenotype_measurement_df[,ordinal_columns]
results_matrix
results_matrix
templeafletlengths_ <- vector(length = 29)
tempnutlengths_ <- vector(length = 29)
tempnutwidth_ <- vector(length = 29)
tempcatkinlength_ <- vector(length = 29)
nrow(results_matrix)
# lines 41 - 73  act as a check to identify individuals where the amount (number of times) of measurements taken the first time do not match up with the amount of measurements take the second time. The comparison method we are trying to do that leads up to the percent change calculation will not work when there are two different amounts of measurements.
# first create vectors that will store the true/false statements across the rows for each continuous column
templeafletlengths_ <- vector(length = nrow(results_matrix))
tempnutlengths_ <- vector(length = nrow(results_matrix))
tempnutwidth_ <- vector(length = nrow(results_matrix))
tempcatkinlength_ <- vector(length = nrow(results_matrix))
# this for loop iterates through each row of a range of columns and takes the sum of measurements that are NA. This is done for the dataset that measured individuals the first time and second time. This outputs a true or false statement and acts is placed in the ith position of the vector.
for (i in 1:nrow(results_matrix)) {
templeafletlengths_[i] <- sum(is.na(final_phenotype_measurement_df[i,17:21]))==sum(is.na(initial_phenotype_measurement_df[i,17:21]))
tempnutlengths_[i] <- sum(is.na(final_phenotype_measurement_df[i,23:27]))==sum(is.na(initial_phenotype_measurement_df[i,23:27]))
tempnutwidth_[i] <- sum(is.na(final_phenotype_measurement_df[i,28:32]))==sum(is.na(initial_phenotype_measurement_df[i,28:32]))
tempcatkinlength_[i] <- sum(is.na(final_phenotype_measurement_df[i,33:37]))==sum(is.na(initial_phenotype_measurement_df[i,33:37]))
}
tempcatkinlength_
# the which statemt telse us
sameLeafletamounts <- which(templeafletlengths_ == TRUE)
sameLeafletamounts
